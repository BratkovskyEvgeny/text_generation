{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1W8R8WgZceEk"
      },
      "source": [
        "# Dracula\n",
        "\n",
        "### Проект по генерации текста в стиле произведения Брэма Стокера \"Дракула\".\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqUOE2flceEl"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wHfCDyzceEl"
      },
      "source": [
        "## Загрузка данных\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/BratkovskyEvgeny/text_generation/main/dracula.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXAxa--jPUSd",
        "outputId": "a6448cba-71d8-4f24-bab8-7c3986c069fb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-01 19:42:07--  https://raw.githubusercontent.com/BratkovskyEvgeny/text_generation/main/dracula.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 874627 (854K) [text/plain]\n",
            "Saving to: ‘dracula.txt’\n",
            "\n",
            "\rdracula.txt           0%[                    ]       0  --.-KB/s               \rdracula.txt         100%[===================>] 854.13K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2024-03-01 19:42:07 (18.1 MB/s) - ‘dracula.txt’ saved [874627/874627]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b34kfqIOceEl"
      },
      "source": [
        "# считывание данных\n",
        "with open(\"dracula.txt\", \"r\") as f:\n",
        "    text = f.read()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VctmLQfceEl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "295de195-bb06-4013-ca95-3215ea0e6ecb"
      },
      "source": [
        "# первые 100 символов\n",
        "text[:100]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Project Gutenberg EBook of Dracula, by Bram Stoker\\n\\nThis eBook is for the use of anyone anywhere'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iC21bopceEl"
      },
      "source": [
        "### Токенизация\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYVlmnxLceEl"
      },
      "source": [
        "# преобразования символов\n",
        "chars = tuple(set(text))\n",
        "\n",
        "int2char = dict(enumerate(chars))\n",
        "char2int = {ch: ii for ii, ch in int2char.items()}\n",
        "\n",
        "# перекодирование\n",
        "encoded = np.array([char2int[ch] for ch in text])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJIzwzSwceEl"
      },
      "source": [
        "Посмотрим как символы закодировались целыми числами"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WK1MYr_9ceEl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d4ca7da-a743-4bc8-8b46-2c04e141a55a"
      },
      "source": [
        "# проверка кодирования символов целыми числами\n",
        "encoded[:100]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3, 81, 30, 26, 46, 40, 17, 32, 30, 13, 51, 26, 63, 47, 51, 30, 45,\n",
              "       72, 30, 40,  2, 26, 71, 36, 17, 17, 23, 26, 17,  8, 26, 58, 40, 33,\n",
              "       13, 47, 21, 33, 29, 26, 72,  5, 26, 36, 40, 33,  1, 26, 50, 51, 17,\n",
              "       23, 30, 40, 61, 61,  3, 81,  9, 49, 26, 30, 36, 17, 17, 23, 26,  9,\n",
              "       49, 26,  8, 17, 40, 26, 51, 81, 30, 26, 47, 49, 30, 26, 17,  8, 26,\n",
              "       33, 45,  5, 17, 45, 30, 26, 33, 45,  5, 20, 81, 30, 40, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azltQy-gceEl"
      },
      "source": [
        "## Препроцессинг\n",
        "\n",
        "Для реализации проекта используется \"char-RNN\". Все символы преобразованы посредством использования OHE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnahALhiceEl"
      },
      "source": [
        "def one_hot_encode(arr, n_labels):\n",
        "\n",
        "    # инициализация массива\n",
        "    one_hot = np.zeros((arr.size, n_labels), dtype=np.float32)\n",
        "\n",
        "    # заполнение единицами\n",
        "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.0\n",
        "\n",
        "    one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
        "\n",
        "    return one_hot"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3lTdLKfceEl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f00f168-378b-4ba8-db0f-aa0b2afe70d0"
      },
      "source": [
        "# проверка функции, что всё работает, как ожидалось\n",
        "test_seq = np.array([[3, 5, 1]])\n",
        "one_hot = one_hot_encode(test_seq, 8)\n",
        "\n",
        "print(one_hot)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0. 0. 0. 0. 0.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YyL91CuceEl"
      },
      "source": [
        "## Мини-батчи\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batches(int_words, batch_size, seq_length):\n",
        "\n",
        "    # усечение текста\n",
        "    window_size = seq_length + 1\n",
        "    batch_size_total = batch_size * window_size\n",
        "    n_batches = len(int_words) // batch_size_total\n",
        "    int_words = int_words[: n_batches * batch_size_total]\n",
        "\n",
        "    # переформирование батчей\n",
        "    int_words = int_words.reshape((batch_size, -1))\n",
        "\n",
        "    # проход по матрице\n",
        "    for position in range(0, int_words.shape[1], window_size):\n",
        "        x = int_words[:, position : position + window_size - 1]\n",
        "        y = int_words[:, position + 1 : position + window_size]\n",
        "        yield x, y"
      ],
      "metadata": {
        "id": "FLBOH8ZQUl7B"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtKlLXi1ceEl"
      },
      "source": [
        "batches = get_batches(encoded, 8, 50)\n",
        "x, y = next(batches)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rg5MUTqqceEl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c53c9a3b-4e4e-426f-a8d1-7ef6df2d5755"
      },
      "source": [
        "# вывод первых 10 элементов\n",
        "print(\"x\\n\", x[:10, :10])\n",
        "print(\"\\ny\\n\", y[:10, :10])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x\n",
            " [[ 3 81 30 26 46 40 17 32 30 13]\n",
            " [ 2 40 30 33 51 26 81 30 33  4]\n",
            " [45 26 13 33 40 30 26 51 81 33]\n",
            " [19 17 45 30 78 68 61 61 25  9]\n",
            " [ 1  4  9 40 30 10 26 26  3 81]\n",
            " [51 26 81 30 26  9 49 26 45 17]\n",
            " [49 81 30 26  2 40 30 20 26  1]\n",
            " [19 33  1 26 41  9 45 33 26 33]]\n",
            "\n",
            "y\n",
            " [[81 30 26 46 40 17 32 30 13 51]\n",
            " [40 30 33 51 26 81 30 33  4 26]\n",
            " [26 13 33 40 30 26 51 81 33 51]\n",
            " [17 45 30 78 68 61 61 25  9 51]\n",
            " [ 4  9 40 30 10 26 26  3 81 30]\n",
            " [26 81 30 26  9 49 26 45 17 26]\n",
            " [81 30 26  2 40 30 20 26  1 17]\n",
            " [33  1 26 41  9 45 33 26 33 45]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jouxv0L2ceEl"
      },
      "source": [
        "\n",
        "## Архитектура\n",
        "\n",
        "\n",
        "<img src=\"https://github.com/udacity/deep-learning-v2-pytorch/blob/master/recurrent-neural-networks/char-rnn/assets/charRNN.png?raw=1\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7s5eRaoceEl"
      },
      "source": [
        "### Структура модели\n",
        "\n",
        "В `__init__` предлагаемая структура выглядит следующим образом:\n",
        "* Создаются и хранятся необходимые словари\n",
        "* определяется слой LSTM, который принимает в качестве параметров: размер ввода (количество символов), размер скрытого слоя `n_hidden`, количество слоев` n_layers`, вероятность drop-out'а `drop_prob` и логическое значение batch_first (True)\n",
        "* Определяется слой drop-out с помощью \"drop_prob\"\n",
        "* Определяется полносвязанный слой с параметрами: размер ввода `n_hidden` и размер выхода - количество символов\n",
        "* инициализируются веса.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Plm1atCuceEl"
      },
      "source": [
        "### LSTM\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlTnDntHceEl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7c43fdf-7a5f-4480-be9e-2c7b025a3f9b"
      },
      "source": [
        "# проверка на наличие GPU\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if train_on_gpu:\n",
        "    print(\"Training on GPU!\")\n",
        "else:\n",
        "    print(\"No GPU available, training on CPU; consider making n_epochs very small.\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on GPU!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPq1EA38rBqn"
      },
      "source": [
        "class CharRNN(nn.Module):\n",
        "    def __init__(self, tokens, n_hidden=256, n_layers=2, drop_prob=0.5, lr=0.001):\n",
        "        super().__init__()\n",
        "        self.drop_prob = drop_prob\n",
        "        self.n_layers = n_layers\n",
        "        self.n_hidden = n_hidden\n",
        "        self.lr = lr\n",
        "\n",
        "        # создание словарей символов\n",
        "        self.chars = tokens\n",
        "        self.int2char = dict(enumerate(self.chars))\n",
        "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
        "\n",
        "        # инициализация LSTM\n",
        "        self.lstm = nn.LSTM(\n",
        "            len(self.chars), n_hidden, n_layers, dropout=drop_prob, batch_first=True\n",
        "        )\n",
        "\n",
        "        # инициализация дропаута\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "\n",
        "        # инициализация слоя\n",
        "        self.fc = nn.Linear(n_hidden, len(self.chars))\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "\n",
        "        # получение выхода и нового скрытого состояние из lstm\n",
        "        r_output, hidden = self.lstm(x, hidden)\n",
        "\n",
        "        out = self.dropout(r_output)\n",
        "\n",
        "        out = out.contiguous().view(-1, self.n_hidden)\n",
        "\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "\n",
        "        weight = next(self.parameters()).data\n",
        "\n",
        "        if train_on_gpu:\n",
        "            hidden = (\n",
        "                weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
        "                weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
        "            )\n",
        "        else:\n",
        "            hidden = (\n",
        "                weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
        "                weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
        "            )\n",
        "\n",
        "        return hidden"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IrBRlEPceEl"
      },
      "source": [
        "## Обучение модели\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lv8VkRI0ceEl"
      },
      "source": [
        "def train(\n",
        "    net,\n",
        "    data,\n",
        "    epochs=10,\n",
        "    batch_size=10,\n",
        "    seq_length=50,\n",
        "    lr=0.001,\n",
        "    clip=5,\n",
        "    val_frac=0.1,\n",
        "    print_every=10,\n",
        "):\n",
        "    \"\"\"\n",
        "    net: CharRNN network\n",
        "    data: text data to train the network\n",
        "    epochs: Number of epochs to train\n",
        "    batch_size: Number of mini-sequences per mini-batch, aka batch size\n",
        "    seq_length: Number of character steps per mini-batch\n",
        "    lr: learning rate\n",
        "    clip: gradient clipping\n",
        "    val_frac: Fraction of data to hold out for validation\n",
        "    print_every: Number of steps for printing training and validation loss\n",
        "\n",
        "    \"\"\"\n",
        "    net.train()\n",
        "\n",
        "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # создание тренировочных, и валидационных данных\n",
        "    val_idx = int(len(data) * (1 - val_frac))\n",
        "    data, val_data = data[:val_idx], data[val_idx:]\n",
        "\n",
        "    if train_on_gpu:\n",
        "        net.cuda()\n",
        "\n",
        "    counter = 0\n",
        "    n_chars = len(net.chars)\n",
        "    for e in range(epochs):\n",
        "        # инициализация скрытого состояния\n",
        "        h = net.init_hidden(batch_size)\n",
        "\n",
        "        for x, y in get_batches(data, batch_size, seq_length):\n",
        "            counter += 1\n",
        "\n",
        "            # OHE\n",
        "            x = one_hot_encode(x, n_chars)\n",
        "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
        "\n",
        "            if train_on_gpu:\n",
        "                inputs, targets = inputs.cuda(), targets.cuda()\n",
        "\n",
        "            h = tuple([each.data for each in h])\n",
        "\n",
        "            net.zero_grad()\n",
        "\n",
        "            output, h = net(inputs, h)\n",
        "\n",
        "            # вычисление лосса\n",
        "            loss = criterion(output, targets.view(batch_size * seq_length).long())\n",
        "            loss.backward()\n",
        "\n",
        "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "            opt.step()\n",
        "\n",
        "            if counter % print_every == 0:\n",
        "                # валидационный лосс\n",
        "                val_h = net.init_hidden(batch_size)\n",
        "                val_losses = []\n",
        "                net.eval()\n",
        "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
        "\n",
        "                    x = one_hot_encode(x, n_chars)\n",
        "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
        "\n",
        "                    val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "                    inputs, targets = x, y\n",
        "                    if train_on_gpu:\n",
        "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
        "\n",
        "                    output, val_h = net(inputs, val_h)\n",
        "                    val_loss = criterion(\n",
        "                        output, targets.view(batch_size * seq_length).long()\n",
        "                    )\n",
        "\n",
        "                    val_losses.append(val_loss.item())\n",
        "\n",
        "                net.train()\n",
        "\n",
        "                print(\n",
        "                    \"Epoch: {}/{}...\".format(e + 1, epochs),\n",
        "                    \"Step: {}...\".format(counter),\n",
        "                    \"Loss: {:.4f}...\".format(loss.item()),\n",
        "                    \"Val Loss: {:.4f}\".format(np.mean(val_losses)),\n",
        "                )"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykMcIloEr3G7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1fac77a-dafd-49e8-fe5e-2f835db5da2b"
      },
      "source": [
        "# гиперпараметры сетки\n",
        "n_hidden = 512\n",
        "n_layers = 2\n",
        "\n",
        "net = CharRNN(chars, n_hidden, n_layers)\n",
        "print(net)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CharRNN(\n",
            "  (lstm): LSTM(85, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=512, out_features=85, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hTkNrWEsjgI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "986d018a-9b26-44ac-af18-e44cca07774c"
      },
      "source": [
        "# гиперпараметры\n",
        "batch_size = 128\n",
        "seq_length = 100\n",
        "n_epochs = 20\n",
        "\n",
        "# обучение\n",
        "train(\n",
        "    net,\n",
        "    encoded,\n",
        "    epochs=n_epochs,\n",
        "    batch_size=batch_size,\n",
        "    seq_length=seq_length,\n",
        "    lr=0.001,\n",
        "    print_every=10,\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/20... Step: 10... Loss: 3.2368... Val Loss: 3.1687\n",
            "Epoch: 1/20... Step: 20... Loss: 3.1537... Val Loss: 3.1145\n",
            "Epoch: 1/20... Step: 30... Loss: 3.0932... Val Loss: 3.1015\n",
            "Epoch: 1/20... Step: 40... Loss: 3.1144... Val Loss: 3.1004\n",
            "Epoch: 1/20... Step: 50... Loss: 3.0997... Val Loss: 3.0996\n",
            "Epoch: 2/20... Step: 60... Loss: 3.0783... Val Loss: 3.0985\n",
            "Epoch: 2/20... Step: 70... Loss: 3.0700... Val Loss: 3.0945\n",
            "Epoch: 2/20... Step: 80... Loss: 3.0955... Val Loss: 3.0925\n",
            "Epoch: 2/20... Step: 90... Loss: 3.0649... Val Loss: 3.0869\n",
            "Epoch: 2/20... Step: 100... Loss: 3.0636... Val Loss: 3.0769\n",
            "Epoch: 2/20... Step: 110... Loss: 3.0361... Val Loss: 3.0542\n",
            "Epoch: 3/20... Step: 120... Loss: 2.9735... Val Loss: 3.0011\n",
            "Epoch: 3/20... Step: 130... Loss: 2.8966... Val Loss: 2.9050\n",
            "Epoch: 3/20... Step: 140... Loss: 2.8569... Val Loss: 2.8722\n",
            "Epoch: 3/20... Step: 150... Loss: 2.7618... Val Loss: 2.7712\n",
            "Epoch: 3/20... Step: 160... Loss: 2.6897... Val Loss: 2.6679\n",
            "Epoch: 3/20... Step: 170... Loss: 2.6248... Val Loss: 2.5972\n",
            "Epoch: 4/20... Step: 180... Loss: 2.5365... Val Loss: 2.5267\n",
            "Epoch: 4/20... Step: 190... Loss: 2.5011... Val Loss: 2.4749\n",
            "Epoch: 4/20... Step: 200... Loss: 2.4483... Val Loss: 2.4324\n",
            "Epoch: 4/20... Step: 210... Loss: 2.4070... Val Loss: 2.4095\n",
            "Epoch: 4/20... Step: 220... Loss: 2.3765... Val Loss: 2.3820\n",
            "Epoch: 4/20... Step: 230... Loss: 2.3552... Val Loss: 2.3585\n",
            "Epoch: 5/20... Step: 240... Loss: 2.3269... Val Loss: 2.3317\n",
            "Epoch: 5/20... Step: 250... Loss: 2.3378... Val Loss: 2.3091\n",
            "Epoch: 5/20... Step: 260... Loss: 2.3333... Val Loss: 2.2865\n",
            "Epoch: 5/20... Step: 270... Loss: 2.2503... Val Loss: 2.2672\n",
            "Epoch: 5/20... Step: 280... Loss: 2.2574... Val Loss: 2.2452\n",
            "Epoch: 5/20... Step: 290... Loss: 2.2094... Val Loss: 2.2296\n",
            "Epoch: 6/20... Step: 300... Loss: 2.2440... Val Loss: 2.2110\n",
            "Epoch: 6/20... Step: 310... Loss: 2.1923... Val Loss: 2.1895\n",
            "Epoch: 6/20... Step: 320... Loss: 2.1725... Val Loss: 2.1709\n",
            "Epoch: 6/20... Step: 330... Loss: 2.1846... Val Loss: 2.1565\n",
            "Epoch: 6/20... Step: 340... Loss: 2.1641... Val Loss: 2.1379\n",
            "Epoch: 6/20... Step: 350... Loss: 2.1121... Val Loss: 2.1230\n",
            "Epoch: 7/20... Step: 360... Loss: 2.1420... Val Loss: 2.1047\n",
            "Epoch: 7/20... Step: 370... Loss: 2.0929... Val Loss: 2.0953\n",
            "Epoch: 7/20... Step: 380... Loss: 2.0899... Val Loss: 2.0804\n",
            "Epoch: 7/20... Step: 390... Loss: 2.0570... Val Loss: 2.0625\n",
            "Epoch: 7/20... Step: 400... Loss: 2.0431... Val Loss: 2.0527\n",
            "Epoch: 7/20... Step: 410... Loss: 2.0320... Val Loss: 2.0375\n",
            "Epoch: 8/20... Step: 420... Loss: 2.0446... Val Loss: 2.0262\n",
            "Epoch: 8/20... Step: 430... Loss: 1.9786... Val Loss: 2.0152\n",
            "Epoch: 8/20... Step: 440... Loss: 2.0531... Val Loss: 2.0016\n",
            "Epoch: 8/20... Step: 450... Loss: 1.9881... Val Loss: 1.9912\n",
            "Epoch: 8/20... Step: 460... Loss: 1.9856... Val Loss: 1.9787\n",
            "Epoch: 8/20... Step: 470... Loss: 1.9572... Val Loss: 1.9672\n",
            "Epoch: 9/20... Step: 480... Loss: 1.9975... Val Loss: 1.9608\n",
            "Epoch: 9/20... Step: 490... Loss: 1.9549... Val Loss: 1.9497\n",
            "Epoch: 9/20... Step: 500... Loss: 1.9487... Val Loss: 1.9386\n",
            "Epoch: 9/20... Step: 510... Loss: 1.9481... Val Loss: 1.9301\n",
            "Epoch: 9/20... Step: 520... Loss: 1.9238... Val Loss: 1.9202\n",
            "Epoch: 9/20... Step: 530... Loss: 1.9108... Val Loss: 1.9119\n",
            "Epoch: 10/20... Step: 540... Loss: 1.9458... Val Loss: 1.8999\n",
            "Epoch: 10/20... Step: 550... Loss: 1.8745... Val Loss: 1.8937\n",
            "Epoch: 10/20... Step: 560... Loss: 1.9076... Val Loss: 1.8847\n",
            "Epoch: 10/20... Step: 570... Loss: 1.8888... Val Loss: 1.8786\n",
            "Epoch: 10/20... Step: 580... Loss: 1.8643... Val Loss: 1.8687\n",
            "Epoch: 10/20... Step: 590... Loss: 1.8459... Val Loss: 1.8593\n",
            "Epoch: 11/20... Step: 600... Loss: 1.8665... Val Loss: 1.8519\n",
            "Epoch: 11/20... Step: 610... Loss: 1.8539... Val Loss: 1.8469\n",
            "Epoch: 11/20... Step: 620... Loss: 1.8457... Val Loss: 1.8397\n",
            "Epoch: 11/20... Step: 630... Loss: 1.8501... Val Loss: 1.8331\n",
            "Epoch: 11/20... Step: 640... Loss: 1.8192... Val Loss: 1.8255\n",
            "Epoch: 12/20... Step: 650... Loss: 1.7900... Val Loss: 1.8178\n",
            "Epoch: 12/20... Step: 660... Loss: 1.7809... Val Loss: 1.8087\n",
            "Epoch: 12/20... Step: 670... Loss: 1.8003... Val Loss: 1.8088\n",
            "Epoch: 12/20... Step: 680... Loss: 1.7734... Val Loss: 1.7976\n",
            "Epoch: 12/20... Step: 690... Loss: 1.7880... Val Loss: 1.7950\n",
            "Epoch: 12/20... Step: 700... Loss: 1.7532... Val Loss: 1.7903\n",
            "Epoch: 13/20... Step: 710... Loss: 1.7672... Val Loss: 1.7803\n",
            "Epoch: 13/20... Step: 720... Loss: 1.7725... Val Loss: 1.7717\n",
            "Epoch: 13/20... Step: 730... Loss: 1.7375... Val Loss: 1.7712\n",
            "Epoch: 13/20... Step: 740... Loss: 1.7615... Val Loss: 1.7603\n",
            "Epoch: 13/20... Step: 750... Loss: 1.7711... Val Loss: 1.7599\n",
            "Epoch: 13/20... Step: 760... Loss: 1.7781... Val Loss: 1.7530\n",
            "Epoch: 14/20... Step: 770... Loss: 1.7501... Val Loss: 1.7446\n",
            "Epoch: 14/20... Step: 780... Loss: 1.7202... Val Loss: 1.7378\n",
            "Epoch: 14/20... Step: 790... Loss: 1.7309... Val Loss: 1.7359\n",
            "Epoch: 14/20... Step: 800... Loss: 1.7077... Val Loss: 1.7295\n",
            "Epoch: 14/20... Step: 810... Loss: 1.6973... Val Loss: 1.7263\n",
            "Epoch: 14/20... Step: 820... Loss: 1.7174... Val Loss: 1.7209\n",
            "Epoch: 15/20... Step: 830... Loss: 1.6990... Val Loss: 1.7137\n",
            "Epoch: 15/20... Step: 840... Loss: 1.6845... Val Loss: 1.7096\n",
            "Epoch: 15/20... Step: 850... Loss: 1.7113... Val Loss: 1.7080\n",
            "Epoch: 15/20... Step: 860... Loss: 1.6876... Val Loss: 1.7028\n",
            "Epoch: 15/20... Step: 870... Loss: 1.6945... Val Loss: 1.6982\n",
            "Epoch: 15/20... Step: 880... Loss: 1.6731... Val Loss: 1.6980\n",
            "Epoch: 16/20... Step: 890... Loss: 1.6813... Val Loss: 1.6892\n",
            "Epoch: 16/20... Step: 900... Loss: 1.6640... Val Loss: 1.6833\n",
            "Epoch: 16/20... Step: 910... Loss: 1.6594... Val Loss: 1.6836\n",
            "Epoch: 16/20... Step: 920... Loss: 1.6878... Val Loss: 1.6776\n",
            "Epoch: 16/20... Step: 930... Loss: 1.6563... Val Loss: 1.6741\n",
            "Epoch: 16/20... Step: 940... Loss: 1.6259... Val Loss: 1.6737\n",
            "Epoch: 17/20... Step: 950... Loss: 1.6630... Val Loss: 1.6646\n",
            "Epoch: 17/20... Step: 960... Loss: 1.6316... Val Loss: 1.6623\n",
            "Epoch: 17/20... Step: 970... Loss: 1.6409... Val Loss: 1.6603\n",
            "Epoch: 17/20... Step: 980... Loss: 1.6338... Val Loss: 1.6553\n",
            "Epoch: 17/20... Step: 990... Loss: 1.6387... Val Loss: 1.6534\n",
            "Epoch: 17/20... Step: 1000... Loss: 1.6171... Val Loss: 1.6528\n",
            "Epoch: 18/20... Step: 1010... Loss: 1.6422... Val Loss: 1.6451\n",
            "Epoch: 18/20... Step: 1020... Loss: 1.5720... Val Loss: 1.6441\n",
            "Epoch: 18/20... Step: 1030... Loss: 1.6573... Val Loss: 1.6395\n",
            "Epoch: 18/20... Step: 1040... Loss: 1.6094... Val Loss: 1.6377\n",
            "Epoch: 18/20... Step: 1050... Loss: 1.6124... Val Loss: 1.6367\n",
            "Epoch: 18/20... Step: 1060... Loss: 1.5867... Val Loss: 1.6348\n",
            "Epoch: 19/20... Step: 1070... Loss: 1.6446... Val Loss: 1.6292\n",
            "Epoch: 19/20... Step: 1080... Loss: 1.6017... Val Loss: 1.6255\n",
            "Epoch: 19/20... Step: 1090... Loss: 1.5975... Val Loss: 1.6227\n",
            "Epoch: 19/20... Step: 1100... Loss: 1.6269... Val Loss: 1.6219\n",
            "Epoch: 19/20... Step: 1110... Loss: 1.6078... Val Loss: 1.6186\n",
            "Epoch: 19/20... Step: 1120... Loss: 1.5921... Val Loss: 1.6161\n",
            "Epoch: 20/20... Step: 1130... Loss: 1.6259... Val Loss: 1.6119\n",
            "Epoch: 20/20... Step: 1140... Loss: 1.5597... Val Loss: 1.6081\n",
            "Epoch: 20/20... Step: 1150... Loss: 1.5942... Val Loss: 1.6075\n",
            "Epoch: 20/20... Step: 1160... Loss: 1.5872... Val Loss: 1.6059\n",
            "Epoch: 20/20... Step: 1170... Loss: 1.5555... Val Loss: 1.6036\n",
            "Epoch: 20/20... Step: 1180... Loss: 1.5406... Val Loss: 1.5972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6RXl5VAceEm"
      },
      "source": [
        "# сохранение модели (понадобится при деплое в веб-сервис)\n",
        "model_name = \"dracula.net\"\n",
        "\n",
        "checkpoint = {\n",
        "    \"n_hidden\": net.n_hidden,\n",
        "    \"n_layers\": net.n_layers,\n",
        "    \"state_dict\": net.state_dict(),\n",
        "    \"tokens\": net.chars,\n",
        "}\n",
        "\n",
        "with open(model_name, \"wb\") as f:\n",
        "    torch.save(checkpoint, f)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2sJhx5iceEm"
      },
      "source": [
        "\n",
        "## Генерация текста\n",
        "\n",
        "Для предсказания передается последний символ и сеть предсказывает следующий символ, который потом передается снова на вход и получается еще 1предсказанный символ и так далее.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEIRW_B2ceEm"
      },
      "source": [
        "def predict(net, char, h=None, top_k=None):\n",
        "\n",
        "    # входы тензора\n",
        "    x = np.array([[net.char2int[char]]])\n",
        "    x = one_hot_encode(x, len(net.chars))\n",
        "    inputs = torch.from_numpy(x)\n",
        "\n",
        "    if train_on_gpu:\n",
        "        inputs = inputs.cuda()\n",
        "\n",
        "    h = tuple([each.data for each in h])\n",
        "    out, h = net(inputs, h)\n",
        "\n",
        "    p = F.softmax(out, dim=1).data\n",
        "    if train_on_gpu:\n",
        "        p = p.cpu()\n",
        "\n",
        "    # получение топ-символов\n",
        "    if top_k is None:\n",
        "        top_ch = np.arange(len(net.chars))\n",
        "    else:\n",
        "        p, top_ch = p.topk(top_k)\n",
        "        top_ch = top_ch.numpy().squeeze()\n",
        "\n",
        "    # выбор вероятного следующего символа с некоторым элементом случайности\n",
        "    p = p.numpy().squeeze()\n",
        "    char = np.random.choice(top_ch, p=p / p.sum())\n",
        "\n",
        "    # возвращает закодированное значение предсказанного символа и скрытого состояния\n",
        "    return net.int2char[char], h"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9vpB5gRceEm"
      },
      "source": [
        "def sample(net, size, prime=\"The\", top_k=None):\n",
        "\n",
        "    if train_on_gpu:\n",
        "        net.cuda()\n",
        "    else:\n",
        "        net.cpu()\n",
        "\n",
        "    net.eval()\n",
        "\n",
        "    chars = [ch for ch in prime]\n",
        "    h = net.init_hidden(1)\n",
        "    for ch in prime:\n",
        "        char, h = predict(net, ch, h, top_k=top_k)\n",
        "\n",
        "    chars.append(char)\n",
        "\n",
        "    for ii in range(size):\n",
        "        char, h = predict(net, chars[-1], h, top_k=top_k)\n",
        "        chars.append(char)\n",
        "\n",
        "    return \"\".join(chars)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqmFA9eEceEm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40506728-7ebd-4352-c0ef-b3faece17c19"
      },
      "source": [
        "print(sample(net, 1000, prime=\"Madam Mina\", top_k=10))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Madam Mina\n",
            "Harking.  I knew when we think, and then he began sould with a crasce, besteer and must way no sounself.  What is hard feart over off to the deep or an'cles of don't time to close, as hilong sturd of aclithen, when I how was, it spoke though mastle opared that wonlight he had dear away be one which he whilether may not sortinct to the room and said free the morsing man forthelf interest, that\n",
            "too his fine of othis big to me, is not inlend\n",
            "of this tried.\n",
            "\n",
            "When I\n",
            "hose todingle the dogathings trathing shatiess in there.  I closed it, friend Got linest be one of the rose were spolan.  And the frees over\n",
            "and fleck about many sunget of seems, but he must ge sleavl at\n",
            "learng of cartitute.\n",
            "\n",
            "\"I child is nom to the deary take it a pluc sear, myself is think is not\n",
            "seemed to my dyard, with much that much said waser with ut face and feel of cloted, and\n",
            "seemed to a play the larghor.  Any he must\n",
            "thought be writele than the\n",
            "concect and setended\n",
            "siling of the sither cire.\n",
            "\n",
            "My forin' found her may not\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выше показан пример генерации текста в стиле произведения Брэма Стокера \"Дракула\". В целом, качество генерации удовлетворительное."
      ],
      "metadata": {
        "id": "vLeFu_yKzXG8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "aZcSJnXuzUII"
      }
    }
  ]
}